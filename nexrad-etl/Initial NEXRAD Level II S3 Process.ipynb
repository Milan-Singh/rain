{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from pyproj import Geod\n",
    "from metpy.io.nexrad import Level2File\n",
    "from metpy.plots import ctables\n",
    "import os, re, boto3\n",
    "from botocore.handlers import disable_signing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "resource = boto3.resource('s3')\n",
    "# Disable signing for anonymous requests to public bucket\n",
    "resource.meta.client.meta.events.register('choose-signer.s3.*', disable_signing)\n",
    "\n",
    "# Pulled from Stack Overflow here: http://stackoverflow.com/a/32674165\n",
    "def folders(client, bucket, prefix=''):\n",
    "    paginator = client.get_paginator('list_objects')\n",
    "    for result in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter='/'):\n",
    "        for prefix in result.get('CommonPrefixes', []):\n",
    "            yield prefix.get('Prefix')\n",
    "\n",
    "def file_list(client, bucket, prefix=''):\n",
    "    paginator = client.get_paginator('list_objects')\n",
    "    for result in client.list_objects(Bucket=bucket, Prefix=prefix, Delimiter='/')['Contents']:\n",
    "        if result.get('Key').endswith('.gz'):\n",
    "            yield result.get('Key')\n",
    "\n",
    "gen_folders = folders(s3_client, 'noaa-nexrad-level2')\n",
    "list(gen_folders)\n",
    "\n",
    "gen_subfolders = folders(s3_client, 'noaa-nexrad-level2', prefix='2015/')\n",
    "list(gen_subfolders)\n",
    "\n",
    "gen_klot_15 = list(file_list(s3_client, 'noaa-nexrad-level2', prefix='2015/08/01/KLOT/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(filepath):\n",
    "    f = Level2File(filepath)\n",
    "    # Pull data out of the file\n",
    "    sweep = 0\n",
    "\n",
    "    # First item in ray is header, which has azimuth angle\n",
    "    try:\n",
    "        az = np.array([ray[0].az_angle for ray in f.sweeps[sweep]])\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "    # 5th item is a dict mapping a var name (byte string) to a tuple\n",
    "    # of (header, data array)\n",
    "    ref_hdr = f.sweeps[sweep][0][4][b'REF'][0]\n",
    "    ref_range = np.arange(ref_hdr.num_gates) * ref_hdr.gate_width + ref_hdr.first_gate\n",
    "    ref = np.array([ray[4][b'REF'][1] for ray in f.sweeps[sweep]])\n",
    "    \n",
    "    data_hdr = f.sweeps[sweep][0][1]\n",
    "    \n",
    "    data = ma.array(ref)\n",
    "    data[data==0] = ma.masked\n",
    "\n",
    "    # Data from MetPy needs to be converted to latitude and longitude coordinates\n",
    "    g = Geod(ellps='clrk66')\n",
    "    center_lat = np.ones([len(az),len(ref_range)])*data_hdr.lat\n",
    "    center_lon = np.ones([len(az),len(ref_range)])*data_hdr.lon\n",
    "\n",
    "    az2D = np.ones_like(center_lat)*az[:,None]\n",
    "    rng2D = np.ones_like(center_lat)*np.transpose(ref_range[:,None])*1000\n",
    "    lon,lat,back = g.fwd(center_lon,center_lat,az2D,rng2D)\n",
    "    \n",
    "    return lon, lat, data\n",
    "\n",
    "def unstack_process(lon, lat, data):\n",
    "    lat_df = pd.DataFrame(lat)\n",
    "    lon_df = pd.DataFrame(lon)\n",
    "    data_df = pd.DataFrame(data)\n",
    "    \n",
    "    lon_stack = lon_df.stack().reset_index()\n",
    "    lon_stack = lon_stack.rename(columns={'level_0': 'x', 'level_1': 'y', 0: 'lon'})\n",
    "    lat_stack = lat_df.stack().reset_index()\n",
    "    lat_stack = lat_stack.rename(columns={'level_0': 'x', 'level_1': 'y', 0: 'lat'})\n",
    "    coord_merge = pd.merge(lat_stack, lon_stack, on=['x', 'y']).reset_index()\n",
    "    # Reducing to bounding box through selection rather than geospatial operation\n",
    "    coord_merge = coord_merge.loc[(coord_merge['lat'] <= 42.0231311) &\n",
    "                                  (coord_merge['lat'] >= 41.644335) &\n",
    "                                  (coord_merge['lon'] <= -87.524044) &\n",
    "                                  (coord_merge['lon'] >= -87.940267)]\n",
    "    data_stack = data_df.stack().reset_index()\n",
    "    data_stack = data_stack.rename(columns={'level_0': 'x', 'level_1': 'y', 0: 'precip'})\n",
    "    merged_data = pd.merge(coord_merge, data_stack, on=['x', 'y'], how='left')[['lat','lon','precip']]\n",
    "    nexrad_df = merged_data.dropna().copy()\n",
    "    # Convert precip in dBZ into mm/hr using Marshall-Palmer https://en.wikipedia.org/wiki/DBZ_(meteorology)\n",
    "    nexrad_df.loc['precip'] = pow(pow(10, nexrad_df['precip']/10)/200, 0.625)\n",
    "    return nexrad_df.dropna()\n",
    "    \n",
    "def spatial_join(nexrad_df, gpd_file, group_col, file_time):\n",
    "    geo_df = gpd.read_file(gpd_file)\n",
    "    crs = {'init':'epsg:4326'}\n",
    "    geo_df.crs = crs\n",
    "    geometry = nexrad_df.apply(lambda z: Point(z['lon'], z['lat']), axis=1).dropna()\n",
    "    #geometry = [Point(xy) for xy in zip(nexrad_df.lon, nexrad_df.lat)]\n",
    "    nexrad_geo = gpd.GeoDataFrame(nexrad_df, crs=crs, geometry=geometry)\n",
    "    nexrad_geo.crs = geo_df.crs\n",
    "    merged_nexrad = gpd.tools.sjoin(nexrad_geo, geo_df, how='right', op='within') #.reset_index()\n",
    "    nexrad_grouped = merged_nexrad.groupby([group_col])['precip'].mean().reset_index()\n",
    "    nexrad_grouped[group_col] = nexrad_grouped[group_col].astype(int)\n",
    "    nexrad_grouped.fillna(value=0, inplace=True)\n",
    "    nexrad_grouped.sort_values(by=group_col, inplace=True)\n",
    "    nexrad_grouped.to_csv('data/nexrad_processed/{}_{}.csv'.format(group_col, file_time), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nexrad_bucket = resource.Bucket('noaa-nexrad-level2')\n",
    "\n",
    "for klot_file in gen_klot_15[15:]:\n",
    "    local_filepath = 'nexrad_data/{}'.format(klot_file.split('/')[-1])\n",
    "    nexrad_bucket.download_file(klot_file, local_filepath)\n",
    "\n",
    "    file_time = re.search(r'\\d{8}_\\d{6}',local_filepath).group()\n",
    "    lon, lat, data = extract_data(local_filepath)\n",
    "    if lon is not None:\n",
    "        print(data.shape)\n",
    "        nexrad_df = unstack_process(lon, lat, data)\n",
    "        spatial_join(nexrad_df, 'data/chicago_wards.geojson', 'ward', file_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
